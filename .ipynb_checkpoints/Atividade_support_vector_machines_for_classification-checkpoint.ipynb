{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e6d454c",
   "metadata": {
    "id": "7e6d454c"
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/nyandwi/machine_learning_complete/blob/main/6_classical_machine_learning_with_scikit-learn/4_support_vector_machines_for_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651045d9",
   "metadata": {
    "id": "651045d9"
   },
   "source": [
    "*This notebook was created by [Jean de Dieu Nyandwi](https://twitter.com/jeande_d) for the love of machine learning community. For any feedback, errors or suggestion, he can be reached on email (johnjw7084 at gmail dot com), [Twitter](https://twitter.com/jeande_d), or [LinkedIn](https://linkedin.com/in/nyandwi).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab8ce3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5ba4fe",
   "metadata": {
    "id": "7c5ba4fe"
   },
   "source": [
    "# Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a262086",
   "metadata": {
    "id": "6a262086"
   },
   "source": [
    "### O que é SVM?\n",
    "\n",
    "**Máquinas de vetores de suporte** são o tipo de algoritmo de aprendizado supervisionado usado para **regressão, classificação e detecção de outliers**;\n",
    "\n",
    "\n",
    "SVMs são notavelmente um dos modelos poderosos no aprendizado de máquina clássico;\n",
    "\n",
    "\n",
    "São adequados para lidar com conjuntos de dados complexos e de alta dimensão;\n",
    "\n",
    "### Quais tipos de dados?\n",
    "O SVM pode lidar com diferentes tipos de conjuntos de dados, tanto **lineares quanto não lineares**;\n",
    "\n",
    "\n",
    "Isso é possível pois o SVM **suporta diferentes kernels** (linear, polinomial, Radial Basis Function (rbf) e sigmóide), \n",
    "\n",
    "### *Embora a matemática por trás dos SVMs esteja além do escopo desta apresentação, aqui está a ideia por trás dos SVMs:*\n",
    "\n",
    "<!-- *A forma como o SVM funciona pode ser comparada a uma rua com uma linha divisória. Durante o treinamento SVM, o SMV traça uma grande margem ou limite de decisão entre as classes com base na importância de cada ponto de dados de treinamento. Os pontos de dados de treinamento que estão dentro do limite de decisão são chamados de vetores de suporte e daí o nome.*\n",
    "\n",
    "![SVM](https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/1200px-Kernel_Machine.svg.png)\n",
    "\n",
    "Fonte da imagem: Wikimedia -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c21740",
   "metadata": {},
   "source": [
    "Primeiro vamos supor que temos um conjunto de pontos como do gráfico abaixo.\n",
    "\n",
    "<img src=\"img/pontos1.png\" alt=\"Exemplo de Imagem\" width = \"500\">\n",
    "\n",
    "<!-- palette = sns.color_palette()\n",
    "\n",
    "x_orange = [0.00, 0.4, 0.08, 0.2, 0.26, 0.3, 0.4, 0.5, 0.6, 0.7, 0.76]\n",
    "x_blue = [1.19, 1.27, 1.35, 1.45, 1.50, 1.57, 1.66, 1.7, 1.75, 1.8, 1.9, 2]\n",
    "y_orange = [0]*len(x_orange)\n",
    "y_blue = [0]*len(x_blue)\n",
    "\n",
    "# Criando o gráfico\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.plot(x_orange + x_blue, y_orange + y_blue, color='black')\n",
    "plt.scatter(x_orange, y_orange, color=palette[1], label='Laranja', zorder=5)\n",
    "plt.scatter(x_blue, y_blue, color=palette[0], label='Azul', zorder=5)\n",
    "plt.xlabel('Eixo X')\n",
    "plt.yticks([])  # Remove o eixo Y\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show() -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca02fe7",
   "metadata": {},
   "source": [
    "No gráfico abaixo entre os pontos roxos e amarelos temos um ponto vermelho. \n",
    "\n",
    "<img src=\"img/pontos2.png\" alt=\"Exemplo de Imagem\" width = \"500\">\n",
    "\n",
    "<!-- palette = sns.color_palette()\n",
    "\n",
    "x_orange = [0.00, 0.4, 0.08, 0.2, 0.26, 0.3, 0.4, 0.5, 0.6, 0.7, 0.76]\n",
    "x_blue = [1.19, 1.27, 1.35, 1.45, 1.50, 1.57, 1.66, 1.7, 1.75, 1.8, 1.9, 2]\n",
    "y_orange = [0]*len(x_orange)\n",
    "y_blue = [0]*len(x_blue)\n",
    "x_red = [0.88]\n",
    "y_red = [0]\n",
    "\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.plot(x_orange + x_blue + x_red, y_orange + y_blue + y_red, color='black')\n",
    "plt.scatter(x_orange, y_orange, color=palette[1], label='Laranja', zorder=5)\n",
    "plt.scatter(x_blue, y_blue, color=palette[0], label='Azul', zorder=5)\n",
    "plt.scatter(x_red, y_red, color='red', zorder=5) #label='Vermelho'\n",
    "plt.xlabel('Eixo X')\n",
    "plt.yticks([])\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show() -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d092813a",
   "metadata": {},
   "source": [
    "### *Qual seria a classificação deste ponto? Laranja ou azul?*\n",
    "\n",
    "<img src=\"img/pontos3.png\" alt=\"Exemplo de Imagem\" width = \"500\">\n",
    "\n",
    "<!-- palette = sns.color_palette()\n",
    "x_orange = [0.00, 0.4, 0.08, 0.2, 0.26, 0.3, 0.4, 0.5, 0.6, 0.7, 0.76, 0.88]  \n",
    "x_blue = [1.19, 1.27, 1.35, 1.45, 1.50, 1.57, 1.66, 1.7, 1.75, 1.8, 1.9, 2] \n",
    "y_orange = [0]*len(x_orange)\n",
    "y_blue = [0]*len(x_blue)\n",
    "\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.plot(x_orange + x_blue, y_orange + y_blue, color='black')\n",
    "plt.scatter(x_orange, y_orange, color=palette[1], label='Laranja', zorder=5)\n",
    "plt.scatter(x_blue, y_blue, color=palette[0], label='Azul', zorder=5)\n",
    "# plt.title('Gráfico com Pontos e Linha de Decisão')\n",
    "plt.xlabel('Eixo X')\n",
    "plt.yticks([])  # Remove o eixo Y\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show() -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b3f03e",
   "metadata": {},
   "source": [
    "Intuitivamente, pela proximidade do ponto vermelho com os pontos laranjas é muito provável a classificação desse ponto é **laranja**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c892b0f",
   "metadata": {},
   "source": [
    "### *Essa lógica é muito parecida com a utilizada no SVM.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd35eb98",
   "metadata": {},
   "source": [
    "Podemos basicamente pegar os pontos que estão mais no extremo dos dados (**os pontos de duas classes diferentes que estão mais próximos entre si**) e usar esses pontos para determinar um <font color='blue'>**hiperplano**</font> capaz de separar essas classes.\n",
    "\n",
    "<!-- **Quanto maior a margem, melhor!** -->\n",
    "\n",
    "### *A pergunta que queremos responder é:*\n",
    "\n",
    "Qual seria o melhor lugar entre os pontos para colocar o nosso <font color='blue'>**limite de separação**</font>?\n",
    "\n",
    "<img src=\"img/limite_de.png\" alt=\"Exemplo de Imagem\" width = \"500\">\n",
    "\n",
    "<!-- palette = sns.color_palette()\n",
    "x_orange = [0.00, 0.4, 0.08, 0.2, 0.26, 0.3, 0.4, 0.5, 0.6, 0.7, 0.76]  \n",
    "x_blue = [1.19, 1.27, 1.35, 1.45, 1.50, 1.57, 1.66, 1.7, 1.75, 1.8, 1.9, 2] \n",
    "y_orange = [0]*len(x_orange)\n",
    "y_blue = [0]*len(x_blue)\n",
    "\n",
    "plt.figure(figsize=(10, 2.2))\n",
    "plt.plot(x_orange + x_blue, y_orange + y_blue, color='black')\n",
    "plt.scatter(x_orange, y_orange, color=palette[1], label='Laranja', zorder=5)\n",
    "plt.scatter(x_blue, y_blue, color=palette[0], label='Azul', zorder=5)\n",
    "# Linha de decisão\n",
    "plt.axvline(x=0.975, color='black', linestyle='--', label='Linha de Decisão')\n",
    "# plt.title('Gráfico com Pontos e Linha de Decisão')\n",
    "plt.xlabel('Eixo X')\n",
    "plt.yticks([])  # Remove o eixo Y\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show() -->\n",
    "\n",
    "Este lugar irá indicar que se o meu ponto for menor do que o valor do limite de decisão então ele vai ser classificado como laranja e se for maior vai ser classificado como azul.\n",
    "\n",
    "Nesta escala nós conseguimos perceber visualmente que talvez este local ou ponto seja o 0,975."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7963b574",
   "metadata": {},
   "source": [
    "### *Conceitualmente o que tem por trás disso que estamos fazendo?*\n",
    "\n",
    "O que o algoritmo vai fazer é pegar os pontos que estão mais extremos, ou seja, os pontos que pertencem a classes diferentes e que tenham a **menor distância** entre eles:\n",
    "\n",
    "<img src=\"img/menor_di.png\" alt=\"Exemplo de Imagem\" width = \"500\">\n",
    "\n",
    "A estes pontos damos o nome de <font color='blue'>**vetores de suporte**</font>\n",
    "\n",
    "<img src=\"img/vetores_su.png\" alt=\"Exemplo de Imagem\" width = \"500\">\n",
    "\n",
    "Os vetores de suporte servem para traçarmos as <font color='blue'>**margens**</font> \n",
    "\n",
    "<img src=\"img/margens.png\" alt=\"Exemplo de Imagem\" width = \"500\">\n",
    "\n",
    "As margens vão definir qual será o nosso <font color='blue'>**hiperplano de separação.**</font>\n",
    "\n",
    "Quanto maior a margem, melhor!\n",
    "\n",
    "<img src=\"img/hiper.png\" alt=\"Exemplo de Imagem\" width = \"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6625d94",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "O limite de decisão não precisa ser uma linha. \n",
    "\n",
    "É possível encontrar o limite de decisão com qualquer número de *features*, não apenas duas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d35380b",
   "metadata": {},
   "source": [
    "#################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba3127f",
   "metadata": {
    "id": "dba3127f"
   },
   "source": [
    "Vamos usar o conjunto de dados de Câncer disponível no **Scikit-Learn**. \n",
    "\n",
    "Este conjunto de dados é amplamente utilizado para problemas de classificação binária.\n",
    "\n",
    "Contém informações de características extraídas de imagens digitalizadas de massas mamárias. \n",
    "\n",
    "O objetivo é classificar as massas como malignas ou benignas com base nas características fornecidas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5e8372",
   "metadata": {
    "id": "ae5e8372"
   },
   "source": [
    "### Contents\n",
    "\n",
    "* [1 - Imports](#1)\n",
    "* [2 - Carregando os dados](#2)\n",
    "* [3 - Análise Exploratória](#3)\n",
    "* [4 - Pré-processamento](#4)\n",
    "* [5 - Training Support Vector Classifier](#5)\n",
    "* [6 - Evaluating Support Vector Classifier](#6)\n",
    "* [7 - Improving Support Vector Classifier](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99058d12",
   "metadata": {
    "id": "99058d12"
   },
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df278c5f",
   "metadata": {
    "id": "df278c5f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35699c38",
   "metadata": {
    "id": "35699c38"
   },
   "source": [
    "## 2 - Carregando os dados\n",
    "\n",
    "Obteremos dados Cancer de conjuntos de dados Sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc2ffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f9f17f",
   "metadata": {
    "id": "51f9f17f"
   },
   "outputs": [],
   "source": [
    "cancer = datasets.load_breast_cancer()\n",
    "X = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "y = pd.Series(cancer.target, name='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1938a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import load_iris\n",
    "# X, y = load_iris(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c492fd93",
   "metadata": {
    "id": "c492fd93"
   },
   "source": [
    "## 3 - Análise Exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b13c0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "49b13c0a",
    "outputId": "d5969868-5b92-4c63-d327-e624c4c359dc"
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de108cd5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "de108cd5",
    "outputId": "e09ce4b6-d399-4d47-ca5b-81fe497ff0d2"
   },
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38de329f",
   "metadata": {},
   "source": [
    "Exibindo a contagem dos valores da coluna alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0a370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando Matplotlib para plotar o gráfico de barras\n",
    "value_counts = y.value_counts()\n",
    "plt.figure(figsize=(8, 4))\n",
    "colors = ['#ff9999','#66b3ff']  # Cores diferentes para as classes\n",
    "value_counts.plot(kind='bar', color=colors)\n",
    "plt.title('Contagem dos Valores Alvo (Target) do Conjunto de Dados Breast Cancer')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Contagem')\n",
    "plt.xticks(ticks=[0, 1], labels=['Maligno', 'Benigno'], rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0479290",
   "metadata": {},
   "source": [
    "Antes de explorar alguns insights sobre os dados, vamos dividi-los em conjunto de teste e conjunto de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d74144",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98d74144",
    "outputId": "d2936592-9a76-41a8-ee02-47b6ba3c57b5"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,random_state=20)\n",
    "\n",
    "print('O tamanho dos dados de treinamento é: {} \\nO tamanho dos dados de teste é: {}'.format(len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323fdf6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "323fdf6a",
    "outputId": "063e8197-c1a0-4f7d-a35f-3ba1b5a79c47"
   },
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2fb26b",
   "metadata": {
    "id": "2d2fb26b"
   },
   "source": [
    "Traçando os histogramas de todos os 4 recursos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046b2586",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "046b2586",
    "outputId": "39dd0a09-dd9d-44d5-fb6b-49eb971e0f0a"
   },
   "outputs": [],
   "source": [
    "X_train.hist(bins=30, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37960aa",
   "metadata": {
    "id": "b37960aa"
   },
   "source": [
    "Plotting the scatter plots of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1d4146",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e1bd0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b35786c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "8b35786c",
    "outputId": "8048025c-1cff-4b88-8eec-97c9759d3564",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=X_train, x='mean radius', y='concavity error', hue=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d8171",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "183d8171",
    "outputId": "998b8627-de37-48a2-b3cc-72b25803c51d"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=X_train, x='mean texture', y='radius error', hue=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189d2be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6733727",
   "metadata": {
    "id": "e6733727"
   },
   "source": [
    "## 4 - Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dec0947",
   "metadata": {
    "id": "9dec0947"
   },
   "source": [
    "<!-- The features already have small values but let's scale them to be between 0 and 1. SVM work well with scaled values. I will set up a pipeline to handle that. -->\n",
    "\n",
    "O SVM funciona bem com valores escalonados. Aqui é feita a configuração para escalar esses valores para ficarem entre 0 e 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3b938b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aa3b938b",
    "outputId": "31e439e3-bd88-442a-967c-c5021d818529",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train.max()\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbbb049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fde6f09",
   "metadata": {
    "id": "9fde6f09"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scale_pipe = Pipeline([\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "X_train_scaled = scale_pipe.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d1d723",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd496de6",
   "metadata": {
    "id": "dd496de6"
   },
   "source": [
    "## 5 - Classificador de vetores de suporte de treinamento\n",
    "\n",
    "Aqui é realizado o treinamento de dois classificadores: Linear SVC e SVC que podemos usar kernels diferentes. SVM suporta kernels `linear`, `polinomial`, `sigmoid` e `rbf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eee090",
   "metadata": {
    "id": "60eee090",
    "outputId": "7cc6b216-cdef-4db2-9426-f135e36865d5"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "lin_svc = LinearSVC()\n",
    "lin_svc.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2dd6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lin_svc.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635886d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "635886d8",
    "outputId": "3b82ae92-0595-4eb5-c0ae-d81e44315810"
   },
   "outputs": [],
   "source": [
    "y.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464b506d",
   "metadata": {
    "id": "464b506d",
    "outputId": "24580dd6-b573-4cd6-c33d-3e8d7a31a153"
   },
   "outputs": [],
   "source": [
    "poly_svc = SVC(kernel='poly')\n",
    "\n",
    "poly_svc.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65395754",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lin_svc.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afb9bde",
   "metadata": {
    "id": "9afb9bde"
   },
   "source": [
    "## 6 - Avaliando o classificador de vetores de suporte\n",
    "\n",
    "Primeiro é importante verificar a precisão do treinamento. Para esta etapa, como estamos tentando encontrar um modelo para melhorar ainda mais, não tocaremos no conjunto de testes ainda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cbc0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_pred, cmap='viridis')\n",
    "plt.title('SVM Classification Results')\n",
    "plt.xlabel(iris.feature_names[0])\n",
    "plt.ylabel(iris.feature_names[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34026c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabdfd07",
   "metadata": {
    "id": "dabdfd07",
    "outputId": "128fea66-eb64-4c8e-c1fe-6f89cdb488b2"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lin_pred = lin_svc.predict(X_train_scaled)\n",
    "\n",
    "accuracy_score(y_train, lin_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc39070a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecd316f",
   "metadata": {
    "id": "0ecd316f",
    "outputId": "a6448519-d2a5-4b3f-d46f-3c8fa1043373"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "poly_pred = poly_svc.predict(X_train_scaled)\n",
    "\n",
    "accuracy_score(y_train, poly_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacdfe4a",
   "metadata": {
    "id": "bacdfe4a"
   },
   "source": [
    "Também podemos exibir a matriz de confusão e o relatório de classificação no SVC com kernel polinomial. O relatório de classificação vai além da exatidão, incluindo recall, precisão e pontuação f1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73865ee0",
   "metadata": {
    "id": "73865ee0",
    "outputId": "3bf4fe14-d7a8-4fdb-db43-d9606237230d"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "confusion_matrix(y_train, poly_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da6526d",
   "metadata": {
    "id": "1da6526d",
    "outputId": "633665d1-eebb-4e9a-e828-13a1518ab3af"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_train, poly_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d777df",
   "metadata": {
    "id": "30d777df"
   },
   "source": [
    "Os resultados são bastante impressionantes, visto que não tivemos que ajustar nenhum hiperparâmetro. Embora isso seja suficiente para nosso conjunto de dados, é improvável que seu modelo funcione bem inicialmente na vida real. Talvez seja necessário ajustar hiperparâmetros.\n",
    "\n",
    "Existem duas técnicas comuns para pesquisa de hiperparâmetros. Estes são Pesquisa Aleatória e GridSearch. No último, usamos Randomized Search, vamos usar GridSearch agora."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a574a5",
   "metadata": {
    "id": "66a574a5"
   },
   "source": [
    "## 7 - Melhorando o classificador de vetores de suporte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b269dadf",
   "metadata": {
    "id": "b269dadf",
    "outputId": "cd3538c3-ecb7-43d3-d90f-ab329e67df68"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params_grid = {'C':[0.001,10,100,1000],\n",
    "              'gamma':[1,0.1,0.01,0.001],\n",
    "                'degree':[2,3,4,5],\n",
    "              'coef0':[0,1,2,4]\n",
    "\n",
    "              }\n",
    "\n",
    "grid_search = GridSearchCV(SVC(kernel='poly'), params_grid, verbose=2)\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80693ba",
   "metadata": {
    "id": "f80693ba",
    "outputId": "22f90c8f-3680-4919-e02c-c09cb0b72592"
   },
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a91201",
   "metadata": {
    "id": "d1a91201"
   },
   "outputs": [],
   "source": [
    "# In grid search definition above, if you set parameter re_fit to True, you won't have to do this\n",
    "\n",
    "poly_best = grid_search.best_estimator_.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f0963c",
   "metadata": {
    "id": "13f0963c"
   },
   "outputs": [],
   "source": [
    "grid_pred = poly_best.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883dc5cb",
   "metadata": {
    "id": "883dc5cb",
    "outputId": "b43daffd-de31-48c0-c4a0-d8e3437ed595"
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_train, grid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4bc41e",
   "metadata": {
    "id": "5e4bc41e",
    "outputId": "18b2bf52-cea0-4817-902c-cd586c7802c1"
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_train, grid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e7012b",
   "metadata": {
    "id": "11e7012b",
    "outputId": "38c9f696-2fe5-43fd-c4b2-e590e52f41d2"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_train, grid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb24269",
   "metadata": {
    "id": "dcb24269"
   },
   "source": [
    "Como você pode ver, nada realmente melhorou. Isso foi apenas com o propósito de aprender como melhorar um modelo, ajustando hiperparâmetros porque na maioria das vezes o primeiro modelo não será bom o suficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ddbcd9",
   "metadata": {
    "id": "39ddbcd9"
   },
   "source": [
    "Depois de melhorar seu modelo, você poderá fazer previsões com segurança no conjunto de testes. Teremos que escalá-lo primeiro, assim como fizemos com o conjunto de treinamento. Lembre-se de que não fazemos `fit_transform`, apenas `transformamos` o conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2ade2f",
   "metadata": {
    "id": "8f2ade2f"
   },
   "outputs": [],
   "source": [
    "test_scaled = scale_pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae077db",
   "metadata": {
    "id": "dae077db"
   },
   "outputs": [],
   "source": [
    "test_pred = poly_best.predict(test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdb3a73",
   "metadata": {
    "id": "fbdb3a73",
    "outputId": "df279e8a-4e4a-4d5f-a2bf-18d53464cbba"
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa0ba3d",
   "metadata": {
    "id": "daa0ba3d",
    "outputId": "35ac2e0a-4b96-444d-be7a-d0b28eca356c"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3215038a",
   "metadata": {
    "id": "3215038a"
   },
   "source": [
    "Vamos ver por que não precisamos ajustar os hiperparâmetros. Se avaliarmos nosso primeiro modelo bom antes da pesquisa de hiperparâmetros, você poderá ver que ele se sai melhor no conjunto de teste do que aquele com hiperparâmetro ajustado.\n",
    "\n",
    "O que isso nos diz? Isso significa que quando estávamos tentando melhorar o modelo, na verdade estávamos superajustando e como resultado o modelo não consegue generalizar bem os novos dados. Se você observar os resultados acima, foi isso que aconteceu.\n",
    "\n",
    "Vamos avaliar nosso primeiro modelo polinomial no conjunto de teste. Foi muito bom mesmo sem ajuste de hiperparâmetros porque a precisão no trem foi de 99%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99504dc6",
   "metadata": {
    "id": "99504dc6"
   },
   "outputs": [],
   "source": [
    "test_pred_poly = poly_svc.predict(test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8b4039",
   "metadata": {
    "id": "ca8b4039",
    "outputId": "9aef2ed9-e566-4a57-fd99-00d16b2c55a0"
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test, test_pred_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf3b9fd",
   "metadata": {
    "id": "0cf3b9fd",
    "outputId": "424c037b-12bc-4df3-e409-74cc7461157a"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, test_pred_poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47757600",
   "metadata": {
    "id": "47757600"
   },
   "source": [
    "Este é o fim do laboratório que tratou do uso de máquinas de vetores de suporte para tarefas de classificação. Como você pode ver, SVM é um algoritmo robusto, dada a forma como suporta diferentes kernels. Esses kernels são o que o tornam adequado para problemas lineares e não lineares. No mundo real, muitos conjuntos de dados não são lineares. Portanto, quando você não conseguir bons resultados com modelos lineares, tente coisas como SVM com kernel polinomial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6536244e",
   "metadata": {
    "id": "6536244e"
   },
   "source": [
    "### [BACK TO TOP](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c2b89d",
   "metadata": {
    "id": "19c2b89d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "def plot_decision_boundary(model, ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    \n",
    "    # create grid to evaluate model\n",
    "    x = np.linspace(xlim[0], xlim[1], 30)\n",
    "    y = np.linspace(ylim[0], ylim[1], 30)\n",
    "    Y, X = np.meshgrid(y, x)\n",
    "\n",
    "# shape data\n",
    "    xy = np.vstack([X.ravel(), Y.ravel()]).T\n",
    "\n",
    "    # get the decision boundary based on the model\n",
    "    P = model.decision_function(xy).reshape(X.shape)\n",
    "    \n",
    "    # plot decision boundary\n",
    "    ax.contour(X, Y, P,\n",
    "               levels=[0], alpha=0.5,\n",
    "               linestyles=['-'])\n",
    "\n",
    "# # linear data\n",
    "# X = np.array([1, 5, 1.5, 8, 1, 9, 7, 8.7, 2.3, 5.5, 7.7, 6.1])\n",
    "# y = np.array([2, 8, 1.8, 8, 0.6, 11, 10, 9.4, 4, 3, 8.8, 7.5])\n",
    "\n",
    "# # show unclassified data\n",
    "# plt.scatter(X, y)\n",
    "# plt.show()\n",
    "\n",
    "# # shaping data for training the model\n",
    "# training_X = np.vstack((X, y)).T\n",
    "# training_y = [0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1]\n",
    "\n",
    "# # define the model\n",
    "# clf = svm.SVC(kernel='linear', C=1.0)\n",
    "\n",
    "# # train the model\n",
    "# clf.fit(training_X, training_y)\n",
    "\n",
    "# # get the weight values for the linear equation from the trained SVM model\n",
    "# w = clf.coef_[0]\n",
    "\n",
    "# # get the y-offset for the linear equation\n",
    "# a = -w[0] / w[1]\n",
    "\n",
    "# # make the x-axis space for the data points\n",
    "# XX = np.linspace(0, 13)\n",
    "\n",
    "# # get the y-values to plot the decision boundary\n",
    "# yy = a * XX - clf.intercept_[0] / w[1]\n",
    "\n",
    "# # plot the decision boundary\n",
    "# plt.plot(XX, yy, 'k-')\n",
    "\n",
    "# # show the plot visually\n",
    "# plt.scatter(training_X[:, 0], training_X[:, 1], c=training_y)\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# non-linear data\n",
    "circle_X, circle_y = datasets.make_circles(n_samples=300, noise=0.05)\n",
    "\n",
    "# show raw non-linear data\n",
    "plt.scatter(circle_X[:, 0], circle_X[:, 1], c=[palette[0] if y == 0 else palette[1] for y in circle_y], marker='.')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# make non-linear algorithm for model\n",
    "nonlinear_clf = svm.SVC(kernel='rbf', C=1.0)\n",
    "\n",
    "# training non-linear model\n",
    "nonlinear_clf.fit(circle_X, circle_y)\n",
    "\n",
    "palette = sns.color_palette()\n",
    "\n",
    "# Plotar dados e linha de decisão\n",
    "plt.scatter(circle_X[:, 0], circle_X[:, 1], c=[palette[0] if y == 0 else palette[1] for y in circle_y], s=50)\n",
    "plot_decision_boundary(nonlinear_clf)\n",
    "# plt.scatter(nonlinear_clf.support_vectors_[:, 0], nonlinear_clf.support_vectors_[:, 1], s=50, lw=1, facecolors='none', edgecolors='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0c98b",
   "metadata": {},
   "source": [
    "# Regressão\n",
    "\n",
    "https://medium.com/turing-talks/turing-talks-12-classifica%C3%A7%C3%A3o-por-svm-f4598094a3f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbfa1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a40ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
